{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fake Review Detection Using Machine Learning\n",
        "\n",
        "## Problem Statement\n",
        "Online review platforms play a critical role in influencing customer decisions. However, many reviews are intentionally fabricated to manipulate product ratings and consumer trust. These fake reviews reduce platform credibility and negatively affect both customers and businesses.\n",
        "\n",
        "Manual detection of fake reviews is impractical due to the large volume of user-generated content. Therefore, automated detection methods using Natural Language Processing (NLP) and Machine Learning are required.\n",
        "\n",
        "## Objective\n",
        "The objective of this project is to build a supervised machine learning model that classifies reviews as **fake** or **genuine** based on their textual content.\n"
      ],
      "metadata": {
        "id": "zqkvMjcInAbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Description\n",
        "The dataset consists of labeled textual reviews. Each review is associated with a binary label indicating whether it is fake or genuine.\n"
      ],
      "metadata": {
        "id": "kzct12NenPjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "!pip install gradio\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"fake reviews dataset.csv\")\n",
        "df.head()\n",
        "df.info()\n",
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bJ7BSKAZnZMA",
        "outputId": "fb46fc55-bbac-46ec-a52f-14280d21f785"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40432 entries, 0 to 40431\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   category  40432 non-null  object \n",
            " 1   rating    40432 non-null  float64\n",
            " 2   label     40432 non-null  object \n",
            " 3   text_     40432 non-null  object \n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 1.2+ MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "CG    20216\n",
              "OR    20216\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CG</th>\n",
              "      <td>20216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OR</th>\n",
              "      <td>20216</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    return text\n",
        "\n",
        "df[\"clean_review\"] = df[\"text_\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "nwMVgxR4C3CN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset distribution shows whether the data is balanced. An imbalanced dataset can affect model performance and evaluation metrics."
      ],
      "metadata": {
        "id": "ZdUsqNH0ncCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing\n",
        "Text preprocessing is necessary to reduce noise and standardize input data before feature extraction.\n"
      ],
      "metadata": {
        "id": "_IGpcSaCnf3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXyQQTdgnqDO",
        "outputId": "3ab3a3a6-49a3-4d05-a885-9f192dcc93bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_review(review):\n",
        "    clean_review = preprocess_text(review)\n",
        "    vect_review = tfidf.transform([clean_review])\n",
        "    pred = model.predict(vect_review)[0]\n",
        "    return \"Fake Review\" if pred == \"OR\" else \"Genuine Review\""
      ],
      "metadata": {
        "id": "xWvNwnMk9SEu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lowercasing reduces vocabulary size. Removing punctuation and numbers eliminates non-semantic tokens. Stopwords are removed to reduce noise. Lemmatization preserves grammatical meaning while normalizing word forms.\n"
      ],
      "metadata": {
        "id": "whIyIj43nsOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train–Test Split\n",
        "The dataset is split into training and testing sets to evaluate model generalization.\n"
      ],
      "metadata": {
        "id": "y4ww3xI-nt-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['text_']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "Um6IqEvhnxUS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction\n",
        "TF-IDF converts text into numerical features by weighting words based on their frequency and importance across documents.\n"
      ],
      "metadata": {
        "id": "OqZrQshunz64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))  # include bigrams\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "X_train_tfidf.shape"
      ],
      "metadata": {
        "id": "mTG38S6rn2Eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3b6799-19cd-4c82-c2fa-c7dddbe1e6cf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32345, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Model\n",
        "Logistic Regression is a strong baseline model for binary text classification due to its simplicity and efficiency."
      ],
      "metadata": {
        "id": "X_JPwZB6n33H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_train = y_train.values if hasattr(y_train, \"values\") else y_train\n",
        "y_test = y_test.values if hasattr(y_test, \"values\") else y_test\n",
        "\n",
        "lr = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    solver=\"liblinear\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "params = {\n",
        "    \"C\": [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=lr,\n",
        "    param_grid=params,\n",
        "    cv=3,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid.fit(X_train_tfidf, y_train)\n",
        "best_model = grid.best_estimator_\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "y_pred = best_model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n"
      ],
      "metadata": {
        "id": "9vBvuncKn8SK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39353aa-dcc4-4058-fafb-9fac88e11f05"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'C': 10}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.93      0.93      0.93      4016\n",
            "          OR       0.93      0.93      0.93      4071\n",
            "\n",
            "    accuracy                           0.93      8087\n",
            "   macro avg       0.93      0.93      0.93      8087\n",
            "weighted avg       0.93      0.93      0.93      8087\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3741  275]\n",
            " [ 295 3776]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(best_model, \"fake_review_lr.pkl\")\n",
        "joblib.dump(tfidf, \"tfidf_vectorizer.pkl\")\n",
        "model = joblib.load(\"fake_review_lr.pkl\")\n",
        "tfidf = joblib.load(\"tfidf_vectorizer.pkl\")"
      ],
      "metadata": {
        "id": "0V0678Ydxx9F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes Model\n",
        "Naive Bayes is commonly used in text classification due to its probabilistic nature and efficiency with high-dimensional data."
      ],
      "metadata": {
        "id": "KukZoAbln9-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "y_pred_nb = nb.predict(X_test_tfidf)\n",
        "\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "confusion_matrix(y_test, y_pred_nb)"
      ],
      "metadata": {
        "id": "jeLMnK2ioACI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47adc2f8-aba0-479b-9c6d-cf6e514cc27a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CG       0.89      0.88      0.89      4016\n",
            "          OR       0.89      0.89      0.89      4071\n",
            "\n",
            "    accuracy                           0.89      8087\n",
            "   macro avg       0.89      0.89      0.89      8087\n",
            "weighted avg       0.89      0.89      0.89      8087\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3551,  465],\n",
              "       [ 448, 3623]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Comparison\n",
        "Both models were evaluated using Accuracy, Precision, Recall, and F1-score.\n",
        "\n",
        "Logistic Regression generally performs better when features are linearly separable, while Naive Bayes assumes feature independence.\n",
        "\n",
        "Based on the evaluation metrics, the better-performing model was selected.\n"
      ],
      "metadata": {
        "id": "C6RCUch7oCLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Load saved model & vectorizer\n",
        "model = joblib.load(\"fake_review_lr.pkl\")\n",
        "tfidf = joblib.load(\"tfidf_vectorizer.pkl\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Streamlit Interface\n",
        "st.title(\"Fake Review Detector\")\n",
        "\n",
        "review = st.text_area(\"Enter a review:\")\n",
        "\n",
        "if st.button(\"Predict\"):\n",
        "    clean_review = preprocess_text(review)\n",
        "    vect_review = tfidf.transform([clean_review])\n",
        "    prediction = model.predict(vect_review)[0]\n",
        "    st.success(\"Fake Review\" if prediction == \"OR\" else \"Genuine Review\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il5tcHAu6wcZ",
        "outputId": "979be1b7-8d2b-4d27-9717-4d624b176680"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Analysis\n",
        "Misclassified reviews were analyzed manually. Some fake reviews resemble genuine opinions, while some real reviews contain exaggerated language, confusing the classifier."
      ],
      "metadata": {
        "id": "YVBvZSVFoIVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ماسک خطاها\n",
        "mask = y_test != y_pred\n",
        "\n",
        "# استخراج نمونه‌های اشتباه\n",
        "error_reviews = X_test[mask].reset_index(drop=True)\n",
        "\n",
        "true_labels = y_test[mask]\n",
        "pred_labels = y_pred[mask]\n",
        "\n",
        "# تعداد امن\n",
        "n = min(5, len(error_reviews))\n",
        "\n",
        "for i in range(n):\n",
        "    print(\"Review:\")\n",
        "    print(error_reviews.iloc[i])\n",
        "    print(\"True Label:\", true_labels[i])\n",
        "    print(\"Predicted Label:\", pred_labels[i])\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(type(X_test))\n",
        "print(type(y_test))\n",
        "print(type(y_pred))\n"
      ],
      "metadata": {
        "id": "InpWaEn5oOD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea35486-e14a-45aa-fe4d-f09d9a28ef18"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review:\n",
            "This is a strong production filled with beautiful and dramatic singing, and Wixell's playing a dual role tightens the story. Some artistic lapses in the directing are made up for by the exceptional final act.\n",
            "True Label: OR\n",
            "Predicted Label: CG\n",
            "--------------------------------------------------------------------------------\n",
            "Review:\n",
            "Our 3 & 1/2 year old have been using them for a month now and have been using them to make homemade Biscuit Chicken, Biscuit Rolls, and other kinds of sandwiches. They are great for baking, which is always a challenge. They are very sturdy and the rubber seal is great for holding the eggs and nuts. I am very happy with this purchase. I would buy them again. I am very pleased with this purchase. I love these bowls! They are so easy to clean, no need for a sponge for it to stay dry. I use them to pour coffee beans or tea into bowls, it doesn't matter if you have a hot water pitcher or a hot water pitcher. I love the color, the color is not as bright as I was expecting it to be, but I really like the color of the bowls. I love the fact that the bowls have a handle that doesn't slide off the bottom of the bowl. This allows you to just pour coffee or tea into the bowl with ease. I don't like that I have to push the handle to push out the water and it keeps the water from getting too hot.\n",
            "True Label: CG\n",
            "Predicted Label: OR\n",
            "--------------------------------------------------------------------------------\n",
            "Review:\n",
            "This is s very enjoyable read . I couldn't put it down. A bit of history combined with modern day interest.  A love a strange love affair that works.\n",
            "True Label: OR\n",
            "Predicted Label: CG\n",
            "--------------------------------------------------------------------------------\n",
            "Review:\n",
            "Great book.  Love this author and will continue to support her work.\n",
            "True Label: OR\n",
            "Predicted Label: CG\n",
            "--------------------------------------------------------------------------------\n",
            "Review:\n",
            "Everything I needed to setup was an AC outlet and a USB power supply.  I was pretty careful with the extra screws and the power\n",
            "True Label: CG\n",
            "Predicted Label: OR\n",
            "--------------------------------------------------------------------------------\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n",
        "The models performed well on structured textual data. However, they struggle with sarcasm, short reviews, and ambiguous language. Dataset size and label quality also affect performance."
      ],
      "metadata": {
        "id": "AbNpcgG3oQP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "This project demonstrated how NLP and machine learning can be used to detect fake reviews. Logistic Regression provided strong baseline performance with interpretable results.\n",
        "\n",
        "## Future Work\n",
        "Future improvements may include:\n",
        "- Deep learning models (LSTM, BERT)\n",
        "- Larger and multilingual datasets\n",
        "- Incorporating reviewer behavior features\n"
      ],
      "metadata": {
        "id": "Qx3tJzd4oWCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_review,       # Function to call\n",
        "    inputs=gr.Textbox(label=\"Enter a review\"),  # Input type\n",
        "    outputs=gr.Textbox(label=\"Prediction\"),    # Output type\n",
        "    title=\"Fake Review Detector\",\n",
        "    description=\"Enter a review and the model will classify it as Fake or Genuine.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "B-i0IXJl61gs",
        "outputId": "9682d870-edff-4c78-e042-08224cd08449"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0a893541eb58f90a22.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0a893541eb58f90a22.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}